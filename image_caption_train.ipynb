{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0819 17:00:06.412602 140572283238208 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. Data generator\n",
    "    a. Load vocab\n",
    "    b. Loads image features\n",
    "    c. provide data for training\n",
    "2. Builds image caption model.\n",
    "3. Trains the model\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import gfile\n",
    "from tensorflow import logging\n",
    "import pprint\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "input_description_file = './flickr30k/results_20130124.token'\n",
    "input_img_feature_dir = './download_inception_v3_features/'\n",
    "input_vocab_file = './flickr30k/vocab.txt'\n",
    "output_dir = './flickr30k/local_run'\n",
    "\n",
    "if not gfile.Exists(output_dir):\n",
    "    gfile.MakeDirs(output_dir)\n",
    "\n",
    "def get_default_params():\n",
    "    return tf.contrib.training.HParams(\n",
    "        num_vocab_word_threshold = 3,\n",
    "        num_embedding_nodes = 32,\n",
    "        num_timesteps = 10,\n",
    "        num_lstm_nodes = [64, 64],\n",
    "        num_lstm_layers = 2,\n",
    "        num_fc_nodes = 32,\n",
    "        batch_size = 80,\n",
    "        cell_type = \"lstm\",\n",
    "        clip_lstm_grads = 1.0,\n",
    "        learning_rate = 0.001,\n",
    "        keep_prob = 0.8,\n",
    "        log_frequent = 100,\n",
    "        save_frequent = 1000,\n",
    "    )\n",
    "\n",
    "hps = get_default_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 10875\n",
      "[1494, 389, 1, 0]\n",
      "'the of man white'\n"
     ]
    }
   ],
   "source": [
    "class Vocab(object):\n",
    "    def __init__(self, filename, word_num_threshold):\n",
    "        self._id_to_word = {}\n",
    "        self._word_to_id = {}\n",
    "        self._unk = -1\n",
    "        self._eos = -1\n",
    "        self._word_num_threshold= word_num_threshold\n",
    "        self._read_dict(filename)\n",
    "        \n",
    "    def _read_dict(self, filename):\n",
    "        with gfile.GFile(filename, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        for line in lines:\n",
    "            word, occurrence = line.strip('\\r\\n').split('\\t')\n",
    "            occurrence = int(occurrence)\n",
    "            if occurrence < self._word_num_threshold:\n",
    "                continue\n",
    "            idx = len(self._id_to_word)\n",
    "            if word == '<UNK>':\n",
    "                self._unk = idx\n",
    "            elif word == '.':\n",
    "                self._eos = idx\n",
    "            if word in self._word_to_id or idx in self._id_to_word:\n",
    "                raise Exception(\"duplicate words in vocab.\")\n",
    "            self._word_to_id[word] = idx\n",
    "            self._id_to_word[idx] = word\n",
    "            \n",
    "    @property\n",
    "    def unk(self):\n",
    "        return self._unk\n",
    "    \n",
    "    @property\n",
    "    def eos(self):\n",
    "        return self._eos\n",
    "    \n",
    "    def word_to_id(self, word):\n",
    "        return self._word_to_id.get(word, self.unk)\n",
    "    \n",
    "    def id_to_word(self, word_id):\n",
    "        return self._id_to_word.get(word_id, '<UNK>')\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self._id_to_word)\n",
    "    \n",
    "    def encode(self, sentence):\n",
    "        return [self.word_to_id(word) for word in sentence.split(' ')]\n",
    "    \n",
    "    def decode(self, sentence_id):\n",
    "        words = [self.id_to_word(word_id) for word_id in sentence_id]\n",
    "        return ' '.join(words)\n",
    "    \n",
    "vocab = Vocab(input_vocab_file, hps.num_vocab_word_threshold)\n",
    "vocab_size = vocab.size()\n",
    "print(\"vocab_size: %d\" % vocab_size)\n",
    "\n",
    "pprint.pprint(vocab.encode(\"I have a dream.\"))\n",
    "pprint.pprint(vocab.decode([5, 10, 9, 20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of all imgs: 31783\n",
      "['A man in jeans is reclining on a green metal bench along a busy sidewalk and '\n",
      " 'crowded street .',\n",
      " 'A white male with a blue sweater and gray pants laying on a sidewalk bench .',\n",
      " 'A man in a blue shirt and gray pants is sleeping on a sidewalk bench .',\n",
      " 'A person is sleeping on a bench , next to cars .',\n",
      " 'A man sleeping on a bench in a city area .']\n",
      "num of all imgs: 31783\n",
      "[[3, 9, 4, 132, 8, 3532, 6, 1, 48, 337, 146, 139, 1, 244, 93, 7, 380, 36, 2],\n",
      " [3, 20, 179, 11, 1, 26, 284, 7, 120, 128, 297, 6, 1, 93, 146, 2],\n",
      " [3, 9, 4, 1, 26, 21, 7, 120, 128, 8, 340, 6, 1, 93, 146, 2],\n",
      " [3, 63, 8, 340, 6, 1, 146, 12, 70, 15, 518, 2],\n",
      " [3, 9, 340, 6, 1, 146, 4, 1, 112, 171, 2]]\n"
     ]
    }
   ],
   "source": [
    "def parse_token_file(token_file):\n",
    "    \"\"\"Parses images description file.\"\"\"\n",
    "    img_name_to_tokens = {}\n",
    "    with gfile.GFile(token_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    for line in lines:\n",
    "        img_id, description = line.strip('\\r\\n').split('\\t')\n",
    "        img_name, _ = img_id.split('#')\n",
    "        img_name_to_tokens.setdefault(img_name, [])\n",
    "        img_name_to_tokens[img_name].append(description)\n",
    "    return img_name_to_tokens\n",
    "\n",
    "def convert_token_to_id(img_name_to_tokens, vocab):\n",
    "    \"\"\"Converts tokens of each description of imgs to id.\"\"\"\n",
    "    img_name_to_tokens_id = {}\n",
    "    for img_name in img_name_to_tokens:\n",
    "        img_name_to_tokens_id.setdefault(img_name, [])\n",
    "        for description in img_name_to_tokens[img_name]:\n",
    "            token_ids = vocab.encode(description)\n",
    "            img_name_to_tokens_id[img_name].append(token_ids)\n",
    "    return img_name_to_tokens_id\n",
    "\n",
    "img_name_to_tokens = parse_token_file(input_description_file)\n",
    "img_name_to_tokens_id = convert_token_to_id(img_name_to_tokens, vocab)\n",
    "\n",
    "print(\"num of all imgs: %d\" % len(img_name_to_tokens))\n",
    "pprint.pprint(img_name_to_tokens['2778832101.jpg'])\n",
    "print(\"num of all imgs: %d\" % len(img_name_to_tokens_id))\n",
    "pprint.pprint(img_name_to_tokens_id['2778832101.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./download_inception_v3_features/image_feature-30.pickle',\n",
      " './download_inception_v3_features/image_feature-28.pickle',\n",
      " './download_inception_v3_features/image_feature-19.pickle',\n",
      " './download_inception_v3_features/image_feature-0.pickle',\n",
      " './download_inception_v3_features/image_feature-16.pickle',\n",
      " './download_inception_v3_features/image_feature-17.pickle',\n",
      " './download_inception_v3_features/image_feature-31.pickle',\n",
      " './download_inception_v3_features/image_feature-5.pickle',\n",
      " './download_inception_v3_features/image_feature-22.pickle',\n",
      " './download_inception_v3_features/image_feature-27.pickle',\n",
      " './download_inception_v3_features/image_feature-2.pickle',\n",
      " './download_inception_v3_features/image_feature-1.pickle',\n",
      " './download_inception_v3_features/image_feature-24.pickle',\n",
      " './download_inception_v3_features/image_feature-7.pickle',\n",
      " './download_inception_v3_features/image_feature-15.pickle',\n",
      " './download_inception_v3_features/image_feature-26.pickle',\n",
      " './download_inception_v3_features/image_feature-23.pickle',\n",
      " './download_inception_v3_features/image_feature-29.pickle',\n",
      " './download_inception_v3_features/image_feature-11.pickle',\n",
      " './download_inception_v3_features/image_feature-9.pickle',\n",
      " './download_inception_v3_features/image_feature-21.pickle',\n",
      " './download_inception_v3_features/image_feature-18.pickle',\n",
      " './download_inception_v3_features/image_feature-8.pickle',\n",
      " './download_inception_v3_features/image_feature-10.pickle',\n",
      " './download_inception_v3_features/image_feature-25.pickle',\n",
      " './download_inception_v3_features/image_feature-20.pickle',\n",
      " './download_inception_v3_features/image_feature-13.pickle',\n",
      " './download_inception_v3_features/image_feature-6.pickle',\n",
      " './download_inception_v3_features/image_feature-4.pickle',\n",
      " './download_inception_v3_features/image_feature-14.pickle',\n",
      " './download_inception_v3_features/image_feature-12.pickle',\n",
      " './download_inception_v3_features/image_feature-3.pickle']\n",
      "loading ./download_inception_v3_features/image_feature-30.pickle\n",
      "loading ./download_inception_v3_features/image_feature-28.pickle\n",
      "loading ./download_inception_v3_features/image_feature-19.pickle\n",
      "loading ./download_inception_v3_features/image_feature-0.pickle\n",
      "loading ./download_inception_v3_features/image_feature-16.pickle\n",
      "loading ./download_inception_v3_features/image_feature-17.pickle\n",
      "loading ./download_inception_v3_features/image_feature-31.pickle\n",
      "loading ./download_inception_v3_features/image_feature-5.pickle\n",
      "loading ./download_inception_v3_features/image_feature-22.pickle\n",
      "loading ./download_inception_v3_features/image_feature-27.pickle\n",
      "loading ./download_inception_v3_features/image_feature-2.pickle\n",
      "loading ./download_inception_v3_features/image_feature-1.pickle\n",
      "loading ./download_inception_v3_features/image_feature-24.pickle\n",
      "loading ./download_inception_v3_features/image_feature-7.pickle\n",
      "loading ./download_inception_v3_features/image_feature-15.pickle\n",
      "loading ./download_inception_v3_features/image_feature-26.pickle\n",
      "loading ./download_inception_v3_features/image_feature-23.pickle\n",
      "loading ./download_inception_v3_features/image_feature-29.pickle\n",
      "loading ./download_inception_v3_features/image_feature-11.pickle\n",
      "loading ./download_inception_v3_features/image_feature-9.pickle\n",
      "loading ./download_inception_v3_features/image_feature-21.pickle\n",
      "loading ./download_inception_v3_features/image_feature-18.pickle\n",
      "loading ./download_inception_v3_features/image_feature-8.pickle\n",
      "loading ./download_inception_v3_features/image_feature-10.pickle\n",
      "loading ./download_inception_v3_features/image_feature-25.pickle\n",
      "loading ./download_inception_v3_features/image_feature-20.pickle\n",
      "loading ./download_inception_v3_features/image_feature-13.pickle\n",
      "loading ./download_inception_v3_features/image_feature-6.pickle\n",
      "loading ./download_inception_v3_features/image_feature-4.pickle\n",
      "loading ./download_inception_v3_features/image_feature-14.pickle\n",
      "loading ./download_inception_v3_features/image_feature-12.pickle\n",
      "loading ./download_inception_v3_features/image_feature-3.pickle\n",
      "(31783, 2048)\n",
      "(31783,)\n",
      "img_feature_dim: 2048\n",
      "caption_data_size: 31783\n",
      "array([[0.39076036, 0.4378178 , 0.12458504, ..., 0.82232594, 0.2614112 ,\n",
      "        0.0604645 ],\n",
      "       [0.2289711 , 0.75145   , 0.25123262, ..., 0.07675233, 0.5290722 ,\n",
      "        0.7404161 ],\n",
      "       [1.3563472 , 0.77970713, 0.15051074, ..., 1.3190771 , 0.57241327,\n",
      "        0.33792448],\n",
      "       [0.49094602, 0.41855562, 0.7429054 , ..., 0.5930329 , 1.6321616 ,\n",
      "        0.03247305],\n",
      "       [0.60698336, 0.56836283, 0.06232078, ..., 0.6570819 , 0.06798305,\n",
      "        0.690443  ]], dtype=float32)\n",
      "array([[ 180, 1587,   19,   14,   32,    4, 1547,    2,    2,    2],\n",
      "       [   3,    9,   11,    1, 2164,    7,  829,    8,  121,   15],\n",
      "       [   3,  179,  560,  624,   51,  181,  497,   75,    2,    2],\n",
      "       [  59,  943,  110,   74,    4,   20,   14,  385,    1,  653],\n",
      "       [   3,    9,    4,    1,   22,  214,  495,    1,   28, 1698]])\n",
      "array([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "array(['162839055.jpg', '2992217972.jpg', '7988459533.jpg',\n",
      "       '3002670780.jpg', '3864288506.jpg'], dtype='<U14')\n"
     ]
    }
   ],
   "source": [
    "class ImageCaptionData(object):\n",
    "    \"\"\"Provides data for image caption model.\"\"\"\n",
    "    def __init__(self, \n",
    "                 img_name_to_tokens_id, \n",
    "                 img_feature_dir, \n",
    "                 num_timesteps, \n",
    "                 vocab,\n",
    "                 deterministic = False):\n",
    "        self._vocab = vocab\n",
    "        self._img_name_to_tokens_id = img_name_to_tokens_id\n",
    "        self._num_timesteps = num_timesteps\n",
    "        self._deterministic = deterministic\n",
    "        self._indicator = 0\n",
    "        \n",
    "        self._img_feature_filenames = []\n",
    "        self._img_feature_data = []\n",
    "        \n",
    "        self._all_img_feature_filepaths = []\n",
    "        for filename in gfile.ListDirectory(img_feature_dir):\n",
    "            self._all_img_feature_filepaths.append(\n",
    "                os.path.join(img_feature_dir, filename))\n",
    "        pprint.pprint(self._all_img_feature_filepaths)\n",
    "        self._load_img_feature_pickle()\n",
    "        \n",
    "        if not self._deterministic:\n",
    "            self._random_shuffle()\n",
    "            \n",
    "    def _load_img_feature_pickle(self):\n",
    "        \"\"\"Loads img feature data from pickle.\"\"\"\n",
    "        for filepath in self._all_img_feature_filepaths:\n",
    "            print(\"loading %s\" % filepath)\n",
    "            with gfile.GFile(filepath, 'rb') as f:\n",
    "                filenames, features = pickle.load(f)\n",
    "                self._img_feature_filenames += filenames\n",
    "                self._img_feature_data.append(features)\n",
    "        # [#(1000, 1, 1, 2048), #(1000, 1, 1, 2048)] -> #(2000, 1, 1, 2048)\n",
    "        self._img_feature_data = np.vstack(self._img_feature_data)\n",
    "        origin_shape = self._img_feature_data.shape\n",
    "        self._img_feature_data = np.reshape(\n",
    "            self._img_feature_data,\n",
    "            (origin_shape[0], origin_shape[3]))\n",
    "        self._img_feature_filenames = np.asarray(self._img_feature_filenames)\n",
    "        print(self._img_feature_data.shape)\n",
    "        print(self._img_feature_filenames.shape)\n",
    "        \n",
    "    def size(self):\n",
    "        return len(self._img_feature_filenames)\n",
    "        \n",
    "    def img_feature_size(self):\n",
    "        return self._img_feature_data.shape[1]\n",
    "        \n",
    "    def _random_shuffle(self):\n",
    "        \"\"\"Shuffle data randomly.\"\"\"\n",
    "        p = np.random.permutation(self.size())\n",
    "        self._img_feature_filenames = self._img_feature_filenames[p]\n",
    "        self._img_feature_data = self._img_feature_data[p]\n",
    "    \n",
    "    def _img_desc(self, batch_filenames):\n",
    "        \"\"\"Gets descriptions for filenames in batch.\"\"\"\n",
    "        batch_sentence_ids = []\n",
    "        batch_weights = []\n",
    "        for filename in batch_filenames:\n",
    "            token_ids_set = self._img_name_to_tokens_id[filename]\n",
    "            chosen_token_ids = random.choice(token_ids_set)\n",
    "            chosen_token_ids_length = len(chosen_token_ids)\n",
    "            \n",
    "            weight = [1 for i in range(chosen_token_ids_length)]\n",
    "            if chosen_token_ids_length >= self._num_timesteps:\n",
    "                chosen_token_ids = chosen_token_ids[0: self._num_timesteps]\n",
    "                weight = weight[0: self._num_timesteps]\n",
    "            else:\n",
    "                remaining_length = self._num_timesteps - chosen_token_ids_length\n",
    "                chosen_token_ids += [self._vocab.eos for i in range(remaining_length)]\n",
    "                weight += [0 for i in range(remaining_length)]\n",
    "            batch_sentence_ids.append(chosen_token_ids)\n",
    "            batch_weights.append(weight)\n",
    "        batch_sentence_ids = np.asarray(batch_sentence_ids)\n",
    "        batch_weights = np.asarray(batch_weights)\n",
    "        return batch_sentence_ids, batch_weights\n",
    "            \n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"Returns next batch data.\"\"\"\n",
    "        end_indicator = self._indicator + batch_size\n",
    "        if end_indicator > self.size():\n",
    "            if not self._deterministic:\n",
    "                self._random_shuffle()\n",
    "            self._indicator = 0\n",
    "            end_indicator = self._indicator + batch_size\n",
    "        assert end_indicator < self.size()\n",
    "        \n",
    "        batch_filenames = self._img_feature_filenames[self._indicator: end_indicator]\n",
    "        batch_img_features = self._img_feature_data[self._indicator: end_indicator]\n",
    "        # sentence_ids: [100, 101, 102, 10, 3, 0, 0, 0] -> [1, 1, 1, 1, 1, 0, 0, 0]\n",
    "        batch_sentence_ids, batch_weights = self._img_desc(batch_filenames)\n",
    "        self._indicator = end_indicator\n",
    "        return batch_img_features, batch_sentence_ids, batch_weights, batch_filenames\n",
    "\n",
    "caption_data = ImageCaptionData(img_name_to_tokens_id, \n",
    "                                input_img_feature_dir,\n",
    "                                hps.num_timesteps,\n",
    "                                vocab)\n",
    "img_feature_dim = caption_data.img_feature_size()\n",
    "caption_data_size = caption_data.size()\n",
    "print(\"img_feature_dim: %d\" % img_feature_dim)\n",
    "print(\"caption_data_size: %d\" % caption_data_size)\n",
    "\n",
    "batch_img_features, batch_sentences_ids, batch_weight, batch_img_names = caption_data.next_batch(5)\n",
    "pprint.pprint(batch_img_features)\n",
    "pprint.pprint(batch_sentences_ids)\n",
    "pprint.pprint(batch_weight)\n",
    "pprint.pprint(batch_img_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0819 17:00:08.677831 140572283238208 deprecation.py:323] From /root/anaconda3/envs/deep_learning/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:507: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "W0819 17:00:08.678607 140572283238208 deprecation.py:323] From <ipython-input-5-a32b20da60aa>:53: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0819 17:00:08.860558 140572283238208 deprecation.py:323] From <ipython-input-5-a32b20da60aa>:4: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0819 17:00:08.863934 140572283238208 deprecation.py:323] From <ipython-input-5-a32b20da60aa>:69: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "W0819 17:00:08.879046 140572283238208 deprecation.py:323] From <ipython-input-5-a32b20da60aa>:73: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "W0819 17:00:09.076938 140572283238208 deprecation.py:506] From /root/anaconda3/envs/deep_learning/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable names: embeddings/embeddings:0\n",
      "variable names: img_feature_embed/dense/kernel:0\n",
      "variable names: img_feature_embed/dense/bias:0\n",
      "variable names: lstm_nn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0\n",
      "variable names: lstm_nn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0\n",
      "variable names: lstm_nn/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0\n",
      "variable names: lstm_nn/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0\n",
      "variable names: fc/fc1/kernel:0\n",
      "variable names: fc/fc1/bias:0\n",
      "variable names: fc/logits/kernel:0\n",
      "variable names: fc/logits/bias:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0819 17:00:09.790738 140572283238208 deprecation.py:323] From /root/anaconda3/envs/deep_learning/lib/python3.7/site-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "def create_rnn_cell(hidden_dim, cell_type):\n",
    "    \"\"\"Return specific cell according to cell_type.\"\"\"\n",
    "    if cell_type == 'lstm':\n",
    "        return tf.contrib.rnn.BasicLSTMCell(hidden_dim, state_is_tuple=True)\n",
    "    elif cell_type == 'gru':\n",
    "        return tf.contrib.rnn.GRUCell(hidden_dim)\n",
    "    else:\n",
    "        raise Exception(\"%s type has not been supported.\" % cell_type)\n",
    "\n",
    "def dropout(cell, keep_prob):\n",
    "    \"\"\"Wrap cell with dropout.\"\"\"\n",
    "    return tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob = keep_prob)\n",
    "\n",
    "def get_train_model(hps, vocab_size, img_feature_dim):\n",
    "    num_timesteps = hps.num_timesteps\n",
    "    batch_size = hps.batch_size\n",
    "    \n",
    "    img_feature = tf.placeholder(tf.float32, (batch_size, img_feature_dim))\n",
    "    \n",
    "    sentence = tf.placeholder(tf.int32, (batch_size, num_timesteps))\n",
    "    \n",
    "    mask = tf.placeholder(tf.int32, (batch_size, num_timesteps))\n",
    "    \n",
    "    keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "    global_step = tf.Variable(tf.zeros([], tf.int32), name=\"global_step\", trainable=False)\n",
    "    \n",
    "    # prediction process:\n",
    "    # sentence: [a, b, c, d, e]\n",
    "    # input: [img, a, b ,c ,d]\n",
    "    # img_feature: [0.4, 0.3, 10, 2]\n",
    "    # predict #1: img_feature -> embedding_img -> lstm -> (a)\n",
    "    # predict #2: a -> embedding_word -> lstm -> (b)\n",
    "    # predict #3: b2 -> embedding_word -> lstm -> (c)\n",
    "    # ...\n",
    "    \n",
    "    # Sets up embedding layer.\n",
    "    embedding_initializer = tf.random_uniform_initializer(-1.0, 1.0)\n",
    "    with tf.variable_scope('embeddings', initializer=embedding_initializer):\n",
    "        embeddings = tf.get_variable(\n",
    "            'embeddings',\n",
    "            [vocab_size, hps.num_embedding_nodes],\n",
    "            tf.float32)\n",
    "        # embed_token_ids: [batch_size, num_timesstep - 1, num_embedding_nodes]\n",
    "        embed_token_ids = tf.nn.embedding_lookup(\n",
    "            embeddings,\n",
    "            sentence[:, 0: num_timesteps - 1])\n",
    "    \n",
    "    img_feature_embed_init = tf.uniform_unit_scaling_initializer(factor=1.0)\n",
    "    \n",
    "    with tf.variable_scope('img_feature_embed', initializer=img_feature_embed_init):\n",
    "        # img_feature: [batch_size, img_feature_dim]\n",
    "        # embed_img: [batch_size, num_embedding_nodes]\n",
    "        embed_img = tf.layers.dense(img_feature, hps.num_embedding_nodes)\n",
    "        \n",
    "        # embed_img: [batch_size, 1, num_embedding_nodes]\n",
    "        embed_img = tf.expand_dims(embed_img, 1)\n",
    "        # embed_input: [batch_size, num_timesteps, num_embedding_nodes]\n",
    "        embed_inputs = tf.concat([embed_img, embed_token_ids], axis=1)\n",
    "        \n",
    "    # Sets up rnn network\n",
    "    scale = 1.0 / math.sqrt(hps.num_embedding_nodes + hps.num_lstm_nodes[-1]) / 4.0\n",
    "    rnn_init = tf.random_uniform_initializer(-scale, scale)\n",
    "    with tf.variable_scope('lstm_nn', initializer=rnn_init):\n",
    "        cells = []\n",
    "        for i in range(hps.num_lstm_layers):\n",
    "            cell = create_rnn_cell(hps.num_lstm_nodes[i], hps.cell_type)\n",
    "            cell = dropout(cell, keep_prob)\n",
    "            cells.append(cell)\n",
    "        cell = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "        \n",
    "        init_state = cell.zero_state(hps.batch_size, tf.float32)\n",
    "        # rnn_outputs: [batch_size, num_timestep, hps.num_lstm_node[-1]]\n",
    "        rnn_outputs, _ = tf.nn.dynamic_rnn(cell, embed_inputs, initial_state=init_state)\n",
    "    # Sets up fully-connected layer.\n",
    "    fc_init = tf.uniform_unit_scaling_initializer(factor=1.0)\n",
    "    with tf.variable_scope('fc', initializer=fc_init):\n",
    "        rnn_outputs_2d = tf.reshape(rnn_outputs, [-1, hps.num_lstm_nodes[-1]])\n",
    "        fc1 = tf.layers.dense(rnn_outputs_2d, hps.num_fc_nodes, name='fc1')\n",
    "        fc1_dropout = tf.contrib.layers.dropout(fc1, keep_prob)\n",
    "        fc1_relu = tf.nn.relu(fc1_dropout)\n",
    "        logits = tf.layers.dense(fc1_relu, vocab_size, name=\"logits\")\n",
    "    # Calculates loss\n",
    "    with tf.variable_scope('loss'):\n",
    "        sentence_flatten = tf.reshape(sentence, [-1])\n",
    "        mask_flatten = tf.reshape(mask, [-1])\n",
    "        mask_sum = tf.reduce_sum(mask_flatten)\n",
    "        \n",
    "        softmax_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=sentence_flatten)\n",
    "        weighted_softmax_loss = tf.multiply(softmax_loss, tf.cast(mask_flatten, tf.float32))\n",
    "        loss = tf.reduce_sum(weighted_softmax_loss) / tf.cast(mask_sum, tf.float32)\n",
    "        prediction = tf.argmax(logits, 1, output_type=tf.int32)\n",
    "        correct_prediction = tf.equal(prediction, sentence_flatten)\n",
    "        weighted_correct_prediction = tf.multiply(tf.cast(correct_prediction, tf.float32), tf.cast(mask_flatten, tf.float32))\n",
    "        accuracy = tf.reduce_sum(weighted_correct_prediction) / tf.cast(mask_sum, tf.float32)\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        \n",
    "    # Defines train op.\n",
    "    with tf.variable_scope('train_op'):\n",
    "        tvars = tf.trainable_variables()\n",
    "        for var in tvars:\n",
    "            print(\"variable names: %s\" % var.name)\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), hps.clip_lstm_grads)\n",
    "        optimizer = tf.train.AdamOptimizer(hps.learning_rate)\n",
    "        train_op = optimizer.apply_gradients(zip(grads, tvars), global_step)\n",
    "        \n",
    "    return ((img_feature, sentence, mask, keep_prob), (loss, accuracy, train_op), global_step)\n",
    "\n",
    "placeholders, matrics, global_step = get_train_model(hps, vocab_size, img_feature_dim)\n",
    "img_feature, sentence, mask, keep_prob = placeholders\n",
    "loss, accuracy, train_op = matrics\n",
    "\n",
    "summary_op = tf.summary.merge_all()\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:   100, loss: 5.971, accu:0.142\n",
      "Step:   200, loss: 5.251, accu:0.173\n",
      "Step:   300, loss: 5.238, accu:0.196\n",
      "Step:   400, loss: 5.154, accu:0.198\n",
      "Step:   500, loss: 5.030, accu:0.229\n",
      "Step:   600, loss: 4.717, accu:0.229\n",
      "Step:   700, loss: 4.638, accu:0.270\n",
      "Step:   800, loss: 4.547, accu:0.282\n",
      "Step:   900, loss: 4.667, accu:0.276\n",
      "Step:  1000, loss: 4.675, accu:0.246\n",
      "Step:  1000, model saved\n",
      "Step:  1100, loss: 4.558, accu:0.273\n",
      "Step:  1200, loss: 4.037, accu:0.322\n",
      "Step:  1300, loss: 4.272, accu:0.317\n",
      "Step:  1400, loss: 4.565, accu:0.276\n",
      "Step:  1500, loss: 4.163, accu:0.302\n",
      "Step:  1600, loss: 4.180, accu:0.300\n",
      "Step:  1700, loss: 4.168, accu:0.304\n",
      "Step:  1800, loss: 4.291, accu:0.289\n",
      "Step:  1900, loss: 3.837, accu:0.311\n",
      "Step:  2000, loss: 4.166, accu:0.280\n",
      "Step:  2000, model saved\n",
      "Step:  2100, loss: 4.357, accu:0.256\n",
      "Step:  2200, loss: 4.074, accu:0.268\n",
      "Step:  2300, loss: 4.345, accu:0.283\n",
      "Step:  2400, loss: 4.237, accu:0.287\n",
      "Step:  2500, loss: 4.052, accu:0.305\n",
      "Step:  2600, loss: 4.018, accu:0.311\n",
      "Step:  2700, loss: 3.970, accu:0.299\n",
      "Step:  2800, loss: 4.020, accu:0.296\n",
      "Step:  2900, loss: 4.111, accu:0.279\n",
      "Step:  3000, loss: 3.925, accu:0.335\n",
      "Step:  3000, model saved\n",
      "Step:  3100, loss: 4.055, accu:0.306\n",
      "Step:  3200, loss: 4.010, accu:0.299\n",
      "Step:  3300, loss: 3.907, accu:0.335\n",
      "Step:  3400, loss: 4.043, accu:0.299\n",
      "Step:  3500, loss: 4.030, accu:0.281\n",
      "Step:  3600, loss: 3.923, accu:0.298\n",
      "Step:  3700, loss: 3.846, accu:0.304\n",
      "Step:  3800, loss: 4.214, accu:0.286\n",
      "Step:  3900, loss: 3.843, accu:0.330\n",
      "Step:  4000, loss: 3.839, accu:0.318\n",
      "Step:  4000, model saved\n",
      "Step:  4100, loss: 3.769, accu:0.336\n",
      "Step:  4200, loss: 4.048, accu:0.304\n",
      "Step:  4300, loss: 3.689, accu:0.363\n",
      "Step:  4400, loss: 3.966, accu:0.296\n",
      "Step:  4500, loss: 4.161, accu:0.299\n",
      "Step:  4600, loss: 3.797, accu:0.322\n",
      "Step:  4700, loss: 4.038, accu:0.314\n",
      "Step:  4800, loss: 3.748, accu:0.325\n",
      "Step:  4900, loss: 3.848, accu:0.322\n",
      "Step:  5000, loss: 3.751, accu:0.322\n",
      "Step:  5000, model saved\n",
      "Step:  5100, loss: 3.769, accu:0.331\n",
      "Step:  5200, loss: 3.766, accu:0.322\n",
      "Step:  5300, loss: 3.814, accu:0.334\n",
      "Step:  5400, loss: 4.211, accu:0.277\n",
      "Step:  5500, loss: 3.840, accu:0.322\n",
      "Step:  5600, loss: 3.670, accu:0.327\n",
      "Step:  5700, loss: 3.680, accu:0.325\n",
      "Step:  5800, loss: 3.567, accu:0.350\n",
      "Step:  5900, loss: 3.733, accu:0.341\n",
      "Step:  6000, loss: 3.493, accu:0.357\n",
      "Step:  6000, model saved\n",
      "Step:  6100, loss: 3.857, accu:0.329\n",
      "Step:  6200, loss: 3.725, accu:0.310\n",
      "Step:  6300, loss: 3.717, accu:0.343\n",
      "Step:  6400, loss: 3.716, accu:0.326\n",
      "Step:  6500, loss: 3.499, accu:0.348\n",
      "Step:  6600, loss: 3.772, accu:0.345\n",
      "Step:  6700, loss: 3.626, accu:0.331\n",
      "Step:  6800, loss: 3.720, accu:0.338\n",
      "Step:  6900, loss: 3.916, accu:0.295\n",
      "Step:  7000, loss: 3.656, accu:0.346\n",
      "Step:  7000, model saved\n",
      "Step:  7100, loss: 3.791, accu:0.330\n",
      "Step:  7200, loss: 3.656, accu:0.317\n",
      "Step:  7300, loss: 3.742, accu:0.352\n",
      "Step:  7400, loss: 3.605, accu:0.352\n",
      "Step:  7500, loss: 3.711, accu:0.330\n",
      "Step:  7600, loss: 3.558, accu:0.350\n",
      "Step:  7700, loss: 3.947, accu:0.303\n",
      "Step:  7800, loss: 3.729, accu:0.308\n",
      "Step:  7900, loss: 3.690, accu:0.344\n",
      "Step:  8000, loss: 3.611, accu:0.356\n",
      "Step:  8000, model saved\n",
      "Step:  8100, loss: 3.640, accu:0.322\n",
      "Step:  8200, loss: 3.398, accu:0.361\n",
      "Step:  8300, loss: 3.608, accu:0.331\n",
      "Step:  8400, loss: 3.614, accu:0.334\n",
      "Step:  8500, loss: 3.401, accu:0.366\n",
      "Step:  8600, loss: 3.514, accu:0.360\n",
      "Step:  8700, loss: 3.463, accu:0.351\n",
      "Step:  8800, loss: 3.590, accu:0.369\n",
      "Step:  8900, loss: 3.642, accu:0.324\n",
      "Step:  9000, loss: 3.346, accu:0.369\n",
      "Step:  9000, model saved\n",
      "Step:  9100, loss: 3.794, accu:0.325\n",
      "Step:  9200, loss: 3.540, accu:0.346\n",
      "Step:  9300, loss: 3.549, accu:0.352\n",
      "Step:  9400, loss: 3.513, accu:0.376\n",
      "Step:  9500, loss: 3.456, accu:0.365\n",
      "Step:  9600, loss: 3.583, accu:0.333\n",
      "Step:  9700, loss: 3.449, accu:0.329\n",
      "Step:  9800, loss: 3.674, accu:0.309\n",
      "Step:  9900, loss: 3.551, accu:0.330\n",
      "Step: 10000, loss: 3.743, accu:0.310\n",
      "Step: 10000, model saved\n",
      "Step: 10100, loss: 3.651, accu:0.349\n",
      "Step: 10200, loss: 3.662, accu:0.335\n",
      "Step: 10300, loss: 3.624, accu:0.338\n",
      "Step: 10400, loss: 3.581, accu:0.330\n",
      "Step: 10500, loss: 3.573, accu:0.347\n",
      "Step: 10600, loss: 3.513, accu:0.324\n",
      "Step: 10700, loss: 3.643, accu:0.326\n",
      "Step: 10800, loss: 3.817, accu:0.300\n",
      "Step: 10900, loss: 3.540, accu:0.357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0819 17:41:02.263978 140572283238208 deprecation.py:323] From /root/anaconda3/envs/deep_learning/lib/python3.7/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 11000, loss: 3.743, accu:0.325\n",
      "Step: 11000, model saved\n",
      "Step: 11100, loss: 3.751, accu:0.321\n",
      "Step: 11200, loss: 3.499, accu:0.350\n",
      "Step: 11300, loss: 3.675, accu:0.327\n",
      "Step: 11400, loss: 3.437, accu:0.368\n",
      "Step: 11500, loss: 3.807, accu:0.306\n",
      "Step: 11600, loss: 3.678, accu:0.305\n",
      "Step: 11700, loss: 3.703, accu:0.311\n",
      "Step: 11800, loss: 3.703, accu:0.317\n",
      "Step: 11900, loss: 3.486, accu:0.352\n",
      "Step: 12000, loss: 3.626, accu:0.325\n",
      "Step: 12000, model saved\n",
      "Step: 12100, loss: 3.444, accu:0.357\n",
      "Step: 12200, loss: 3.575, accu:0.334\n",
      "Step: 12300, loss: 3.594, accu:0.346\n",
      "Step: 12400, loss: 3.420, accu:0.339\n",
      "Step: 12500, loss: 3.658, accu:0.346\n",
      "Step: 12600, loss: 3.568, accu:0.361\n",
      "Step: 12700, loss: 3.762, accu:0.338\n",
      "Step: 12800, loss: 3.575, accu:0.334\n",
      "Step: 12900, loss: 3.360, accu:0.354\n",
      "Step: 13000, loss: 3.482, accu:0.355\n",
      "Step: 13000, model saved\n",
      "Step: 13100, loss: 3.585, accu:0.363\n",
      "Step: 13200, loss: 3.511, accu:0.369\n",
      "Step: 13300, loss: 3.494, accu:0.339\n",
      "Step: 13400, loss: 3.694, accu:0.310\n",
      "Step: 13500, loss: 3.645, accu:0.330\n",
      "Step: 13600, loss: 3.780, accu:0.303\n",
      "Step: 13700, loss: 3.459, accu:0.352\n",
      "Step: 13800, loss: 3.572, accu:0.359\n",
      "Step: 13900, loss: 3.935, accu:0.317\n",
      "Step: 14000, loss: 3.578, accu:0.331\n",
      "Step: 14000, model saved\n",
      "Step: 14100, loss: 3.498, accu:0.366\n",
      "Step: 14200, loss: 3.539, accu:0.354\n",
      "Step: 14300, loss: 3.427, accu:0.365\n",
      "Step: 14400, loss: 3.396, accu:0.335\n",
      "Step: 14500, loss: 3.630, accu:0.316\n",
      "Step: 14600, loss: 3.612, accu:0.354\n",
      "Step: 14700, loss: 3.593, accu:0.345\n",
      "Step: 14800, loss: 3.533, accu:0.340\n",
      "Step: 14900, loss: 3.495, accu:0.343\n",
      "Step: 15000, loss: 3.382, accu:0.347\n",
      "Step: 15000, model saved\n",
      "Step: 15100, loss: 3.664, accu:0.326\n",
      "Step: 15200, loss: 3.461, accu:0.336\n",
      "Step: 15300, loss: 3.396, accu:0.380\n",
      "Step: 15400, loss: 3.740, accu:0.321\n",
      "Step: 15500, loss: 3.438, accu:0.351\n",
      "Step: 15600, loss: 3.310, accu:0.365\n",
      "Step: 15700, loss: 3.758, accu:0.303\n",
      "Step: 15800, loss: 3.581, accu:0.336\n",
      "Step: 15900, loss: 3.457, accu:0.355\n",
      "Step: 16000, loss: 3.449, accu:0.325\n",
      "Step: 16000, model saved\n",
      "Step: 16100, loss: 3.494, accu:0.360\n",
      "Step: 16200, loss: 3.444, accu:0.363\n",
      "Step: 16300, loss: 3.507, accu:0.320\n",
      "Step: 16400, loss: 3.698, accu:0.336\n",
      "Step: 16500, loss: 3.604, accu:0.327\n",
      "Step: 16600, loss: 3.458, accu:0.368\n",
      "Step: 16700, loss: 3.640, accu:0.324\n",
      "Step: 16800, loss: 3.316, accu:0.375\n",
      "Step: 16900, loss: 3.690, accu:0.329\n",
      "Step: 17000, loss: 3.599, accu:0.339\n",
      "Step: 17000, model saved\n",
      "Step: 17100, loss: 3.545, accu:0.333\n",
      "Step: 17200, loss: 3.604, accu:0.312\n",
      "Step: 17300, loss: 3.664, accu:0.327\n",
      "Step: 17400, loss: 3.440, accu:0.346\n",
      "Step: 17500, loss: 3.370, accu:0.354\n",
      "Step: 17600, loss: 3.525, accu:0.340\n",
      "Step: 17700, loss: 3.639, accu:0.331\n",
      "Step: 17800, loss: 3.551, accu:0.345\n",
      "Step: 17900, loss: 3.278, accu:0.368\n",
      "Step: 18000, loss: 3.498, accu:0.357\n",
      "Step: 18000, model saved\n",
      "Step: 18100, loss: 3.291, accu:0.387\n",
      "Step: 18200, loss: 3.393, accu:0.359\n",
      "Step: 18300, loss: 3.371, accu:0.354\n",
      "Step: 18400, loss: 3.568, accu:0.330\n",
      "Step: 18500, loss: 3.335, accu:0.343\n",
      "Step: 18600, loss: 3.608, accu:0.345\n",
      "Step: 18700, loss: 3.552, accu:0.355\n",
      "Step: 18800, loss: 3.437, accu:0.352\n",
      "Step: 18900, loss: 3.556, accu:0.349\n",
      "Step: 19000, loss: 3.571, accu:0.345\n",
      "Step: 19000, model saved\n",
      "Step: 19100, loss: 3.622, accu:0.331\n",
      "Step: 19200, loss: 3.405, accu:0.347\n",
      "Step: 19300, loss: 3.393, accu:0.369\n",
      "Step: 19400, loss: 3.577, accu:0.333\n",
      "Step: 19600, loss: 3.289, accu:0.355\n",
      "Step: 19700, loss: 3.237, accu:0.363\n",
      "Step: 19800, loss: 3.344, accu:0.344\n",
      "Step: 19900, loss: 3.589, accu:0.327\n",
      "Step: 20000, loss: 3.599, accu:0.344\n",
      "Step: 20000, model saved\n",
      "Step: 20100, loss: 3.558, accu:0.336\n",
      "Step: 20200, loss: 3.358, accu:0.354\n",
      "Step: 20300, loss: 3.552, accu:0.340\n",
      "Step: 20400, loss: 3.290, accu:0.373\n",
      "Step: 20500, loss: 3.127, accu:0.363\n",
      "Step: 20600, loss: 3.289, accu:0.355\n",
      "Step: 20700, loss: 3.505, accu:0.357\n",
      "Step: 20800, loss: 3.367, accu:0.355\n",
      "Step: 20900, loss: 3.429, accu:0.344\n",
      "Step: 21000, loss: 3.455, accu:0.340\n",
      "Step: 21000, model saved\n",
      "Step: 21100, loss: 3.354, accu:0.365\n",
      "Step: 21200, loss: 3.658, accu:0.329\n",
      "Step: 21300, loss: 3.420, accu:0.363\n",
      "Step: 21400, loss: 3.609, accu:0.326\n",
      "Step: 21500, loss: 3.223, accu:0.373\n",
      "Step: 21600, loss: 3.536, accu:0.344\n",
      "Step: 21700, loss: 3.548, accu:0.325\n",
      "Step: 21800, loss: 3.409, accu:0.326\n",
      "Step: 21900, loss: 3.457, accu:0.354\n",
      "Step: 22000, loss: 3.336, accu:0.356\n",
      "Step: 22000, model saved\n",
      "Step: 22100, loss: 3.439, accu:0.336\n",
      "Step: 22200, loss: 3.613, accu:0.345\n",
      "Step: 22300, loss: 3.329, accu:0.357\n",
      "Step: 22400, loss: 3.518, accu:0.346\n",
      "Step: 22500, loss: 3.459, accu:0.343\n",
      "Step: 22600, loss: 3.411, accu:0.356\n",
      "Step: 22700, loss: 3.497, accu:0.344\n",
      "Step: 22800, loss: 3.360, accu:0.357\n",
      "Step: 22900, loss: 3.540, accu:0.335\n",
      "Step: 23000, loss: 3.573, accu:0.336\n",
      "Step: 23000, model saved\n",
      "Step: 23100, loss: 3.399, accu:0.368\n",
      "Step: 23200, loss: 3.691, accu:0.316\n",
      "Step: 23300, loss: 3.371, accu:0.344\n",
      "Step: 23400, loss: 3.426, accu:0.364\n",
      "Step: 23500, loss: 3.527, accu:0.350\n",
      "Step: 23600, loss: 3.446, accu:0.360\n",
      "Step: 23700, loss: 3.341, accu:0.350\n",
      "Step: 23800, loss: 3.276, accu:0.375\n",
      "Step: 23900, loss: 3.522, accu:0.335\n",
      "Step: 24000, loss: 3.515, accu:0.350\n",
      "Step: 24000, model saved\n",
      "Step: 24100, loss: 3.320, accu:0.389\n",
      "Step: 24200, loss: 3.484, accu:0.354\n",
      "Step: 24300, loss: 3.211, accu:0.375\n",
      "Step: 24400, loss: 3.527, accu:0.361\n",
      "Step: 24500, loss: 3.360, accu:0.359\n",
      "Step: 24600, loss: 3.425, accu:0.341\n",
      "Step: 24700, loss: 3.339, accu:0.351\n",
      "Step: 24800, loss: 3.456, accu:0.333\n",
      "Step: 24900, loss: 3.557, accu:0.344\n",
      "Step: 25000, loss: 3.289, accu:0.363\n",
      "Step: 25000, model saved\n",
      "Step: 25100, loss: 3.483, accu:0.344\n",
      "Step: 25200, loss: 3.534, accu:0.321\n",
      "Step: 25300, loss: 3.267, accu:0.374\n",
      "Step: 25400, loss: 3.186, accu:0.379\n",
      "Step: 25500, loss: 3.328, accu:0.351\n",
      "Step: 25600, loss: 3.428, accu:0.340\n",
      "Step: 25700, loss: 3.618, accu:0.324\n",
      "Step: 25800, loss: 3.454, accu:0.336\n",
      "Step: 25900, loss: 3.526, accu:0.339\n",
      "Step: 26000, loss: 3.555, accu:0.340\n",
      "Step: 26000, model saved\n",
      "Step: 26100, loss: 3.221, accu:0.379\n",
      "Step: 26200, loss: 3.501, accu:0.346\n",
      "Step: 26300, loss: 3.395, accu:0.338\n",
      "Step: 26400, loss: 3.362, accu:0.380\n",
      "Step: 26500, loss: 3.438, accu:0.344\n",
      "Step: 26600, loss: 3.457, accu:0.351\n",
      "Step: 26700, loss: 3.437, accu:0.374\n",
      "Step: 26800, loss: 3.503, accu:0.352\n",
      "Step: 26900, loss: 3.408, accu:0.346\n",
      "Step: 27000, loss: 3.468, accu:0.303\n",
      "Step: 27000, model saved\n",
      "Step: 27100, loss: 3.329, accu:0.377\n",
      "Step: 27200, loss: 3.288, accu:0.364\n",
      "Step: 27300, loss: 3.413, accu:0.365\n",
      "Step: 27400, loss: 3.719, accu:0.326\n",
      "Step: 27500, loss: 3.424, accu:0.361\n",
      "Step: 27600, loss: 3.361, accu:0.374\n",
      "Step: 27700, loss: 3.354, accu:0.376\n",
      "Step: 27800, loss: 3.271, accu:0.364\n",
      "Step: 27900, loss: 3.363, accu:0.352\n",
      "Step: 28000, loss: 3.553, accu:0.346\n",
      "Step: 28000, model saved\n",
      "Step: 28100, loss: 3.410, accu:0.376\n",
      "Step: 28200, loss: 3.501, accu:0.370\n",
      "Step: 28300, loss: 3.364, accu:0.350\n",
      "Step: 28400, loss: 3.295, accu:0.396\n",
      "Step: 28500, loss: 3.183, accu:0.371\n",
      "Step: 28600, loss: 3.584, accu:0.347\n",
      "Step: 28700, loss: 3.379, accu:0.351\n",
      "Step: 28800, loss: 3.443, accu:0.339\n",
      "Step: 28900, loss: 3.380, accu:0.361\n",
      "Step: 29000, loss: 3.610, accu:0.309\n",
      "Step: 29000, model saved\n",
      "Step: 29100, loss: 3.289, accu:0.371\n",
      "Step: 29200, loss: 3.446, accu:0.344\n",
      "Step: 29300, loss: 3.313, accu:0.354\n",
      "Step: 29400, loss: 3.476, accu:0.330\n",
      "Step: 29500, loss: 3.301, accu:0.390\n",
      "Step: 29600, loss: 3.343, accu:0.339\n",
      "Step: 29700, loss: 3.170, accu:0.363\n",
      "Step: 29800, loss: 3.131, accu:0.368\n",
      "Step: 29900, loss: 3.324, accu:0.360\n",
      "Step: 30000, loss: 3.490, accu:0.331\n",
      "Step: 30000, model saved\n",
      "Step: 30100, loss: 3.661, accu:0.329\n",
      "Step: 30200, loss: 3.419, accu:0.350\n",
      "Step: 30300, loss: 3.097, accu:0.381\n",
      "Step: 30400, loss: 3.418, accu:0.361\n",
      "Step: 30500, loss: 3.346, accu:0.360\n",
      "Step: 30600, loss: 3.246, accu:0.368\n",
      "Step: 30700, loss: 3.441, accu:0.351\n",
      "Step: 30800, loss: 3.362, accu:0.356\n",
      "Step: 30900, loss: 3.452, accu:0.320\n",
      "Step: 31000, loss: 3.464, accu:0.344\n",
      "Step: 31000, model saved\n",
      "Step: 31100, loss: 3.323, accu:0.384\n",
      "Step: 31200, loss: 3.433, accu:0.329\n",
      "Step: 31300, loss: 3.418, accu:0.361\n",
      "Step: 31400, loss: 3.508, accu:0.341\n",
      "Step: 31500, loss: 3.659, accu:0.330\n",
      "Step: 31600, loss: 3.539, accu:0.334\n",
      "Step: 31700, loss: 3.412, accu:0.329\n",
      "Step: 31800, loss: 3.373, accu:0.334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 31900, loss: 3.206, accu:0.389\n",
      "Step: 32000, loss: 3.347, accu:0.361\n",
      "Step: 32000, model saved\n",
      "Step: 32100, loss: 3.167, accu:0.389\n",
      "Step: 32200, loss: 3.427, accu:0.347\n",
      "Step: 32300, loss: 3.297, accu:0.363\n",
      "Step: 32400, loss: 3.359, accu:0.380\n",
      "Step: 32500, loss: 3.479, accu:0.326\n",
      "Step: 32600, loss: 3.272, accu:0.359\n",
      "Step: 32700, loss: 3.309, accu:0.373\n",
      "Step: 32800, loss: 3.216, accu:0.377\n",
      "Step: 32900, loss: 3.424, accu:0.350\n",
      "Step: 33000, loss: 3.367, accu:0.361\n",
      "Step: 33000, model saved\n",
      "Step: 33100, loss: 3.464, accu:0.360\n",
      "Step: 33200, loss: 3.300, accu:0.357\n",
      "Step: 33300, loss: 3.637, accu:0.329\n",
      "Step: 33400, loss: 3.394, accu:0.344\n",
      "Step: 33500, loss: 3.303, accu:0.365\n",
      "Step: 33600, loss: 3.275, accu:0.354\n",
      "Step: 33700, loss: 3.563, accu:0.304\n",
      "Step: 33800, loss: 3.459, accu:0.364\n",
      "Step: 33900, loss: 3.423, accu:0.354\n",
      "Step: 34000, loss: 3.232, accu:0.381\n",
      "Step: 34000, model saved\n",
      "Step: 34100, loss: 3.384, accu:0.360\n",
      "Step: 34200, loss: 3.416, accu:0.344\n",
      "Step: 34300, loss: 3.293, accu:0.347\n",
      "Step: 34400, loss: 3.404, accu:0.354\n",
      "Step: 34500, loss: 3.405, accu:0.375\n",
      "Step: 34600, loss: 3.593, accu:0.299\n",
      "Step: 34700, loss: 3.422, accu:0.352\n",
      "Step: 34800, loss: 3.302, accu:0.373\n",
      "Step: 34900, loss: 3.500, accu:0.354\n",
      "Step: 35000, loss: 3.359, accu:0.373\n",
      "Step: 35000, model saved\n",
      "Step: 35100, loss: 3.342, accu:0.371\n",
      "Step: 35200, loss: 3.324, accu:0.359\n",
      "Step: 35300, loss: 3.253, accu:0.364\n",
      "Step: 35400, loss: 3.353, accu:0.369\n",
      "Step: 35500, loss: 3.434, accu:0.360\n",
      "Step: 35600, loss: 3.400, accu:0.354\n",
      "Step: 35700, loss: 3.093, accu:0.403\n",
      "Step: 35800, loss: 3.198, accu:0.366\n",
      "Step: 35900, loss: 3.407, accu:0.359\n",
      "Step: 36000, loss: 3.265, accu:0.374\n",
      "Step: 36000, model saved\n",
      "Step: 36100, loss: 3.295, accu:0.364\n",
      "Step: 36200, loss: 3.309, accu:0.341\n",
      "Step: 36300, loss: 3.503, accu:0.343\n",
      "Step: 36400, loss: 3.411, accu:0.365\n",
      "Step: 36500, loss: 3.321, accu:0.373\n",
      "Step: 36600, loss: 3.270, accu:0.364\n",
      "Step: 36700, loss: 3.437, accu:0.335\n",
      "Step: 36800, loss: 3.324, accu:0.377\n",
      "Step: 36900, loss: 3.285, accu:0.346\n",
      "Step: 37000, loss: 3.430, accu:0.331\n",
      "Step: 37000, model saved\n",
      "Step: 37100, loss: 3.529, accu:0.349\n",
      "Step: 37200, loss: 3.290, accu:0.369\n",
      "Step: 37300, loss: 3.348, accu:0.390\n",
      "Step: 37400, loss: 3.174, accu:0.380\n",
      "Step: 37500, loss: 3.402, accu:0.381\n",
      "Step: 37600, loss: 3.488, accu:0.366\n",
      "Step: 37700, loss: 3.174, accu:0.379\n",
      "Step: 37800, loss: 3.466, accu:0.340\n",
      "Step: 37900, loss: 3.481, accu:0.330\n",
      "Step: 38000, loss: 3.304, accu:0.363\n",
      "Step: 38000, model saved\n",
      "Step: 38100, loss: 3.256, accu:0.349\n",
      "Step: 38200, loss: 3.313, accu:0.371\n",
      "Step: 38300, loss: 3.342, accu:0.370\n",
      "Step: 38400, loss: 3.216, accu:0.377\n",
      "Step: 38500, loss: 3.447, accu:0.341\n",
      "Step: 38600, loss: 3.345, accu:0.361\n",
      "Step: 38700, loss: 3.553, accu:0.343\n",
      "Step: 38800, loss: 3.481, accu:0.349\n",
      "Step: 38900, loss: 3.282, accu:0.347\n",
      "Step: 39000, loss: 3.359, accu:0.355\n",
      "Step: 39000, model saved\n",
      "Step: 39100, loss: 3.159, accu:0.384\n",
      "Step: 39200, loss: 3.419, accu:0.371\n",
      "Step: 39300, loss: 3.358, accu:0.343\n",
      "Step: 39400, loss: 3.411, accu:0.357\n",
      "Step: 39500, loss: 3.408, accu:0.354\n",
      "Step: 39600, loss: 3.547, accu:0.339\n",
      "Step: 39700, loss: 3.330, accu:0.376\n",
      "Step: 39800, loss: 3.264, accu:0.374\n",
      "Step: 39900, loss: 3.299, accu:0.349\n",
      "Step: 40000, loss: 3.392, accu:0.374\n",
      "Step: 40000, model saved\n",
      "Step: 40100, loss: 3.331, accu:0.377\n",
      "Step: 40200, loss: 3.434, accu:0.359\n",
      "Step: 40300, loss: 3.490, accu:0.349\n",
      "Step: 40400, loss: 3.256, accu:0.373\n",
      "Step: 40500, loss: 3.229, accu:0.345\n",
      "Step: 40600, loss: 3.608, accu:0.329\n",
      "Step: 40700, loss: 3.136, accu:0.386\n",
      "Step: 40800, loss: 3.311, accu:0.345\n",
      "Step: 40900, loss: 3.242, accu:0.384\n",
      "Step: 41000, loss: 3.168, accu:0.371\n",
      "Step: 41000, model saved\n",
      "Step: 41100, loss: 3.332, accu:0.359\n",
      "Step: 41200, loss: 3.374, accu:0.360\n",
      "Step: 41300, loss: 3.419, accu:0.365\n",
      "Step: 41400, loss: 3.213, accu:0.369\n",
      "Step: 41500, loss: 3.440, accu:0.339\n",
      "Step: 41600, loss: 3.352, accu:0.344\n",
      "Step: 41700, loss: 3.425, accu:0.334\n",
      "Step: 41800, loss: 3.353, accu:0.352\n",
      "Step: 41900, loss: 3.242, accu:0.371\n",
      "Step: 42000, loss: 3.305, accu:0.379\n",
      "Step: 42000, model saved\n",
      "Step: 42100, loss: 3.443, accu:0.346\n",
      "Step: 42200, loss: 3.446, accu:0.341\n",
      "Step: 42300, loss: 3.298, accu:0.364\n",
      "Step: 42400, loss: 3.166, accu:0.396\n",
      "Step: 42500, loss: 3.188, accu:0.361\n",
      "Step: 42600, loss: 3.470, accu:0.352\n",
      "Step: 42700, loss: 3.372, accu:0.354\n",
      "Step: 42800, loss: 3.495, accu:0.324\n",
      "Step: 42900, loss: 3.292, accu:0.364\n",
      "Step: 43000, loss: 3.474, accu:0.316\n",
      "Step: 43000, model saved\n",
      "Step: 43100, loss: 3.309, accu:0.374\n",
      "Step: 43200, loss: 3.344, accu:0.365\n",
      "Step: 43300, loss: 3.121, accu:0.374\n",
      "Step: 43400, loss: 3.378, accu:0.364\n",
      "Step: 43500, loss: 3.271, accu:0.370\n",
      "Step: 43600, loss: 3.474, accu:0.346\n",
      "Step: 43700, loss: 3.123, accu:0.390\n",
      "Step: 43800, loss: 3.335, accu:0.376\n",
      "Step: 43900, loss: 3.127, accu:0.395\n",
      "Step: 44000, loss: 3.341, accu:0.346\n",
      "Step: 44000, model saved\n",
      "Step: 44100, loss: 3.127, accu:0.381\n",
      "Step: 44200, loss: 3.396, accu:0.354\n",
      "Step: 44300, loss: 3.196, accu:0.356\n",
      "Step: 44400, loss: 3.280, accu:0.366\n",
      "Step: 44500, loss: 3.310, accu:0.364\n",
      "Step: 44600, loss: 3.496, accu:0.346\n",
      "Step: 44700, loss: 3.388, accu:0.360\n",
      "Step: 44800, loss: 2.971, accu:0.400\n",
      "Step: 44900, loss: 3.488, accu:0.352\n",
      "Step: 45000, loss: 3.473, accu:0.335\n",
      "Step: 45000, model saved\n",
      "Step: 45100, loss: 3.254, accu:0.349\n",
      "Step: 45200, loss: 3.307, accu:0.352\n",
      "Step: 45300, loss: 3.406, accu:0.380\n",
      "Step: 45400, loss: 3.202, accu:0.361\n",
      "Step: 45500, loss: 3.279, accu:0.376\n",
      "Step: 45600, loss: 3.280, accu:0.355\n",
      "Step: 45700, loss: 3.212, accu:0.385\n",
      "Step: 45800, loss: 3.367, accu:0.333\n",
      "Step: 45900, loss: 3.303, accu:0.366\n",
      "Step: 46000, loss: 3.438, accu:0.339\n",
      "Step: 46000, model saved\n",
      "Step: 46100, loss: 3.375, accu:0.370\n",
      "Step: 46200, loss: 3.105, accu:0.373\n",
      "Step: 46300, loss: 3.273, accu:0.373\n",
      "Step: 46400, loss: 3.310, accu:0.382\n",
      "Step: 46500, loss: 3.419, accu:0.347\n",
      "Step: 46600, loss: 3.302, accu:0.377\n",
      "Step: 46700, loss: 3.315, accu:0.352\n",
      "Step: 46800, loss: 3.243, accu:0.368\n",
      "Step: 46900, loss: 3.281, accu:0.360\n",
      "Step: 47000, loss: 3.379, accu:0.361\n",
      "Step: 47000, model saved\n",
      "Step: 47100, loss: 3.294, accu:0.364\n",
      "Step: 47200, loss: 3.337, accu:0.339\n",
      "Step: 47300, loss: 3.313, accu:0.366\n",
      "Step: 47400, loss: 3.243, accu:0.381\n",
      "Step: 47500, loss: 3.088, accu:0.382\n",
      "Step: 47600, loss: 3.408, accu:0.334\n",
      "Step: 47700, loss: 3.244, accu:0.379\n",
      "Step: 47800, loss: 3.114, accu:0.387\n",
      "Step: 47900, loss: 3.301, accu:0.382\n",
      "Step: 48000, loss: 3.474, accu:0.356\n",
      "Step: 48000, model saved\n",
      "Step: 48100, loss: 3.269, accu:0.389\n",
      "Step: 48200, loss: 3.168, accu:0.387\n",
      "Step: 48300, loss: 3.373, accu:0.350\n",
      "Step: 48400, loss: 3.349, accu:0.355\n",
      "Step: 48500, loss: 3.341, accu:0.343\n",
      "Step: 48600, loss: 3.483, accu:0.345\n",
      "Step: 48700, loss: 3.190, accu:0.351\n",
      "Step: 48800, loss: 3.519, accu:0.346\n",
      "Step: 48900, loss: 3.384, accu:0.336\n",
      "Step: 49000, loss: 3.266, accu:0.356\n",
      "Step: 49000, model saved\n",
      "Step: 49100, loss: 3.410, accu:0.361\n",
      "Step: 49200, loss: 3.127, accu:0.360\n",
      "Step: 49300, loss: 3.347, accu:0.361\n",
      "Step: 49400, loss: 3.527, accu:0.327\n",
      "Step: 49500, loss: 3.267, accu:0.368\n",
      "Step: 49600, loss: 3.145, accu:0.407\n",
      "Step: 49700, loss: 3.365, accu:0.371\n",
      "Step: 49800, loss: 3.548, accu:0.317\n",
      "Step: 49900, loss: 3.339, accu:0.371\n",
      "Step: 50000, loss: 3.379, accu:0.352\n",
      "Step: 50000, model saved\n",
      "Step: 50100, loss: 3.301, accu:0.350\n",
      "Step: 50200, loss: 3.198, accu:0.377\n",
      "Step: 50300, loss: 3.426, accu:0.384\n",
      "Step: 50400, loss: 3.150, accu:0.373\n",
      "Step: 50500, loss: 3.559, accu:0.333\n",
      "Step: 50600, loss: 3.135, accu:0.365\n",
      "Step: 50700, loss: 3.437, accu:0.331\n",
      "Step: 50800, loss: 3.190, accu:0.387\n",
      "Step: 50900, loss: 3.353, accu:0.347\n",
      "Step: 51000, loss: 3.367, accu:0.340\n",
      "Step: 51000, model saved\n",
      "Step: 51100, loss: 3.437, accu:0.326\n",
      "Step: 51200, loss: 3.365, accu:0.349\n",
      "Step: 51300, loss: 3.173, accu:0.391\n",
      "Step: 51400, loss: 3.344, accu:0.352\n",
      "Step: 51500, loss: 3.288, accu:0.374\n",
      "Step: 51600, loss: 3.496, accu:0.335\n",
      "Step: 51700, loss: 3.099, accu:0.379\n",
      "Step: 51800, loss: 3.308, accu:0.364\n",
      "Step: 51900, loss: 3.384, accu:0.334\n",
      "Step: 52000, loss: 3.421, accu:0.329\n",
      "Step: 52000, model saved\n",
      "Step: 52100, loss: 3.398, accu:0.379\n",
      "Step: 52200, loss: 3.362, accu:0.363\n",
      "Step: 52300, loss: 3.504, accu:0.355\n",
      "Step: 52400, loss: 3.392, accu:0.370\n",
      "Step: 52500, loss: 3.340, accu:0.354\n",
      "Step: 52600, loss: 3.136, accu:0.394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 52700, loss: 3.277, accu:0.369\n",
      "Step: 52800, loss: 3.428, accu:0.361\n",
      "Step: 52900, loss: 3.290, accu:0.363\n",
      "Step: 53000, loss: 3.253, accu:0.361\n",
      "Step: 53000, model saved\n",
      "Step: 53100, loss: 3.448, accu:0.344\n",
      "Step: 53200, loss: 3.369, accu:0.356\n",
      "Step: 53300, loss: 3.257, accu:0.352\n",
      "Step: 53400, loss: 3.236, accu:0.381\n",
      "Step: 53500, loss: 3.178, accu:0.393\n",
      "Step: 53600, loss: 3.424, accu:0.333\n",
      "Step: 53700, loss: 3.405, accu:0.356\n",
      "Step: 53800, loss: 3.225, accu:0.354\n",
      "Step: 53900, loss: 3.275, accu:0.363\n",
      "Step: 54000, loss: 3.511, accu:0.344\n",
      "Step: 54000, model saved\n",
      "Step: 54100, loss: 3.220, accu:0.364\n",
      "Step: 54200, loss: 3.325, accu:0.366\n",
      "Step: 54300, loss: 3.289, accu:0.373\n",
      "Step: 54400, loss: 3.516, accu:0.359\n",
      "Step: 54500, loss: 3.325, accu:0.364\n",
      "Step: 54600, loss: 3.289, accu:0.365\n",
      "Step: 54700, loss: 3.429, accu:0.333\n",
      "Step: 54800, loss: 3.391, accu:0.356\n",
      "Step: 54900, loss: 3.405, accu:0.350\n",
      "Step: 55000, loss: 3.574, accu:0.347\n",
      "Step: 55000, model saved\n",
      "Step: 55100, loss: 3.220, accu:0.363\n",
      "Step: 55200, loss: 3.209, accu:0.389\n",
      "Step: 55300, loss: 3.170, accu:0.370\n",
      "Step: 55400, loss: 3.316, accu:0.368\n",
      "Step: 55500, loss: 3.375, accu:0.395\n",
      "Step: 55600, loss: 3.248, accu:0.387\n",
      "Step: 55700, loss: 3.353, accu:0.361\n",
      "Step: 55800, loss: 3.384, accu:0.346\n",
      "Step: 55900, loss: 3.199, accu:0.381\n",
      "Step: 56000, loss: 3.096, accu:0.370\n",
      "Step: 56000, model saved\n",
      "Step: 56100, loss: 3.353, accu:0.331\n",
      "Step: 56200, loss: 3.346, accu:0.324\n",
      "Step: 56300, loss: 3.071, accu:0.347\n",
      "Step: 56400, loss: 3.175, accu:0.377\n",
      "Step: 56500, loss: 3.505, accu:0.335\n",
      "Step: 56600, loss: 3.429, accu:0.347\n",
      "Step: 56700, loss: 3.284, accu:0.371\n",
      "Step: 56800, loss: 3.260, accu:0.355\n",
      "Step: 56900, loss: 3.169, accu:0.374\n",
      "Step: 57000, loss: 3.371, accu:0.357\n",
      "Step: 57000, model saved\n",
      "Step: 57100, loss: 3.076, accu:0.386\n",
      "Step: 57200, loss: 3.422, accu:0.361\n",
      "Step: 57300, loss: 3.449, accu:0.330\n",
      "Step: 57400, loss: 3.381, accu:0.341\n",
      "Step: 57500, loss: 3.293, accu:0.361\n",
      "Step: 57600, loss: 3.210, accu:0.360\n",
      "Step: 57700, loss: 3.237, accu:0.374\n",
      "Step: 57800, loss: 3.336, accu:0.359\n",
      "Step: 57900, loss: 3.336, accu:0.347\n",
      "Step: 58000, loss: 3.354, accu:0.365\n",
      "Step: 58000, model saved\n",
      "Step: 58100, loss: 3.123, accu:0.382\n",
      "Step: 58200, loss: 3.023, accu:0.386\n",
      "Step: 58300, loss: 3.415, accu:0.335\n",
      "Step: 58400, loss: 3.368, accu:0.354\n",
      "Step: 58500, loss: 3.386, accu:0.365\n",
      "Step: 58600, loss: 3.256, accu:0.349\n",
      "Step: 58700, loss: 3.338, accu:0.380\n",
      "Step: 58800, loss: 3.115, accu:0.394\n",
      "Step: 58900, loss: 3.184, accu:0.371\n",
      "Step: 59000, loss: 3.207, accu:0.377\n",
      "Step: 59000, model saved\n",
      "Step: 59100, loss: 3.362, accu:0.338\n",
      "Step: 59200, loss: 3.320, accu:0.331\n",
      "Step: 59300, loss: 3.190, accu:0.352\n",
      "Step: 59400, loss: 3.409, accu:0.351\n",
      "Step: 59500, loss: 3.183, accu:0.375\n",
      "Step: 59600, loss: 3.297, accu:0.371\n",
      "Step: 59700, loss: 3.234, accu:0.371\n",
      "Step: 59800, loss: 3.455, accu:0.329\n",
      "Step: 59900, loss: 3.280, accu:0.361\n",
      "Step: 60000, loss: 3.354, accu:0.363\n",
      "Step: 60000, model saved\n",
      "Step: 60100, loss: 2.972, accu:0.394\n",
      "Step: 60200, loss: 3.210, accu:0.376\n",
      "Step: 60300, loss: 3.154, accu:0.394\n",
      "Step: 60400, loss: 3.401, accu:0.335\n",
      "Step: 60500, loss: 3.284, accu:0.356\n",
      "Step: 60600, loss: 3.259, accu:0.381\n",
      "Step: 60700, loss: 3.190, accu:0.384\n",
      "Step: 60800, loss: 3.162, accu:0.380\n",
      "Step: 60900, loss: 3.401, accu:0.341\n",
      "Step: 61000, loss: 3.346, accu:0.351\n",
      "Step: 61000, model saved\n",
      "Step: 61100, loss: 3.231, accu:0.370\n",
      "Step: 61200, loss: 3.286, accu:0.347\n",
      "Step: 61300, loss: 3.217, accu:0.366\n",
      "Step: 61400, loss: 3.164, accu:0.374\n",
      "Step: 61500, loss: 3.370, accu:0.373\n",
      "Step: 61600, loss: 3.304, accu:0.366\n",
      "Step: 61700, loss: 3.135, accu:0.357\n",
      "Step: 61800, loss: 3.325, accu:0.371\n",
      "Step: 61900, loss: 3.306, accu:0.354\n",
      "Step: 62000, loss: 3.273, accu:0.389\n",
      "Step: 62000, model saved\n",
      "Step: 62100, loss: 3.377, accu:0.349\n",
      "Step: 62200, loss: 3.177, accu:0.395\n",
      "Step: 62300, loss: 3.204, accu:0.373\n",
      "Step: 62400, loss: 3.302, accu:0.355\n",
      "Step: 62500, loss: 3.381, accu:0.352\n",
      "Step: 62600, loss: 3.365, accu:0.354\n",
      "Step: 62700, loss: 3.094, accu:0.373\n",
      "Step: 62800, loss: 3.300, accu:0.320\n",
      "Step: 62900, loss: 3.309, accu:0.363\n",
      "Step: 63000, loss: 3.279, accu:0.368\n",
      "Step: 63000, model saved\n",
      "Step: 63100, loss: 3.451, accu:0.329\n",
      "Step: 63200, loss: 3.431, accu:0.345\n",
      "Step: 63300, loss: 3.374, accu:0.379\n",
      "Step: 63400, loss: 3.268, accu:0.381\n",
      "Step: 63500, loss: 3.272, accu:0.377\n",
      "Step: 63600, loss: 3.239, accu:0.373\n",
      "Step: 63700, loss: 3.372, accu:0.371\n",
      "Step: 63800, loss: 3.249, accu:0.363\n",
      "Step: 63900, loss: 3.297, accu:0.363\n",
      "Step: 64000, loss: 3.200, accu:0.386\n",
      "Step: 64000, model saved\n",
      "Step: 64100, loss: 3.322, accu:0.361\n",
      "Step: 64200, loss: 3.170, accu:0.377\n",
      "Step: 64300, loss: 3.305, accu:0.386\n",
      "Step: 64400, loss: 3.123, accu:0.405\n",
      "Step: 64500, loss: 3.313, accu:0.360\n",
      "Step: 64600, loss: 3.312, accu:0.356\n",
      "Step: 64700, loss: 3.203, accu:0.365\n",
      "Step: 64800, loss: 3.234, accu:0.360\n",
      "Step: 64900, loss: 3.191, accu:0.389\n",
      "Step: 65000, loss: 3.300, accu:0.343\n",
      "Step: 65000, model saved\n",
      "Step: 65100, loss: 3.420, accu:0.352\n",
      "Step: 65200, loss: 3.286, accu:0.365\n",
      "Step: 65300, loss: 3.280, accu:0.357\n",
      "Step: 65400, loss: 3.405, accu:0.361\n",
      "Step: 65500, loss: 3.017, accu:0.365\n",
      "Step: 65600, loss: 3.462, accu:0.351\n",
      "Step: 65700, loss: 3.265, accu:0.376\n",
      "Step: 65800, loss: 3.259, accu:0.374\n",
      "Step: 65900, loss: 3.364, accu:0.351\n",
      "Step: 66000, loss: 3.441, accu:0.347\n",
      "Step: 66000, model saved\n",
      "Step: 66100, loss: 3.198, accu:0.375\n",
      "Step: 66200, loss: 3.146, accu:0.384\n",
      "Step: 66300, loss: 3.212, accu:0.368\n",
      "Step: 66400, loss: 3.134, accu:0.386\n",
      "Step: 66500, loss: 3.091, accu:0.403\n",
      "Step: 66600, loss: 3.481, accu:0.349\n",
      "Step: 66700, loss: 3.436, accu:0.355\n",
      "Step: 66800, loss: 3.203, accu:0.380\n",
      "Step: 66900, loss: 3.347, accu:0.356\n",
      "Step: 67000, loss: 3.165, accu:0.384\n",
      "Step: 67000, model saved\n",
      "Step: 67100, loss: 3.454, accu:0.350\n",
      "Step: 67200, loss: 3.284, accu:0.355\n",
      "Step: 67300, loss: 3.107, accu:0.365\n",
      "Step: 67400, loss: 3.174, accu:0.377\n",
      "Step: 67500, loss: 3.582, accu:0.324\n",
      "Step: 67600, loss: 3.338, accu:0.369\n",
      "Step: 67700, loss: 3.275, accu:0.351\n",
      "Step: 67800, loss: 3.228, accu:0.370\n",
      "Step: 67900, loss: 3.311, accu:0.376\n",
      "Step: 68000, loss: 3.207, accu:0.374\n",
      "Step: 68000, model saved\n",
      "Step: 68100, loss: 3.414, accu:0.364\n",
      "Step: 68200, loss: 3.105, accu:0.376\n",
      "Step: 68300, loss: 3.303, accu:0.360\n",
      "Step: 68400, loss: 3.081, accu:0.363\n",
      "Step: 68500, loss: 3.193, accu:0.382\n",
      "Step: 68600, loss: 3.395, accu:0.336\n",
      "Step: 68700, loss: 3.306, accu:0.360\n",
      "Step: 68800, loss: 3.357, accu:0.354\n",
      "Step: 68900, loss: 3.417, accu:0.344\n",
      "Step: 69000, loss: 3.314, accu:0.354\n",
      "Step: 69000, model saved\n",
      "Step: 69100, loss: 3.263, accu:0.398\n",
      "Step: 69200, loss: 3.298, accu:0.357\n",
      "Step: 69300, loss: 3.318, accu:0.343\n",
      "Step: 69400, loss: 3.258, accu:0.376\n",
      "Step: 69500, loss: 3.224, accu:0.371\n",
      "Step: 69600, loss: 3.238, accu:0.381\n",
      "Step: 69700, loss: 3.492, accu:0.308\n",
      "Step: 69800, loss: 3.174, accu:0.373\n",
      "Step: 69900, loss: 3.188, accu:0.376\n",
      "Step: 70000, loss: 3.275, accu:0.351\n",
      "Step: 70000, model saved\n",
      "Step: 70100, loss: 3.405, accu:0.344\n",
      "Step: 70200, loss: 3.227, accu:0.385\n",
      "Step: 70300, loss: 3.371, accu:0.345\n",
      "Step: 70400, loss: 3.471, accu:0.331\n",
      "Step: 70500, loss: 3.284, accu:0.366\n",
      "Step: 70600, loss: 3.120, accu:0.366\n",
      "Step: 70700, loss: 3.341, accu:0.341\n",
      "Step: 70800, loss: 3.228, accu:0.370\n",
      "Step: 70900, loss: 3.326, accu:0.345\n",
      "Step: 71000, loss: 3.086, accu:0.391\n",
      "Step: 71000, model saved\n",
      "Step: 71100, loss: 3.173, accu:0.373\n",
      "Step: 71200, loss: 3.492, accu:0.346\n",
      "Step: 71300, loss: 3.274, accu:0.373\n",
      "Step: 71400, loss: 3.597, accu:0.338\n",
      "Step: 71500, loss: 3.288, accu:0.361\n",
      "Step: 71600, loss: 3.206, accu:0.377\n",
      "Step: 71700, loss: 3.231, accu:0.371\n",
      "Step: 71800, loss: 3.223, accu:0.377\n",
      "Step: 71900, loss: 3.283, accu:0.366\n",
      "Step: 72000, loss: 3.305, accu:0.375\n",
      "Step: 72000, model saved\n",
      "Step: 72100, loss: 3.225, accu:0.363\n",
      "Step: 72200, loss: 3.220, accu:0.371\n",
      "Step: 72300, loss: 3.253, accu:0.382\n",
      "Step: 72400, loss: 3.192, accu:0.364\n",
      "Step: 72500, loss: 3.252, accu:0.376\n",
      "Step: 72600, loss: 3.326, accu:0.333\n",
      "Step: 72700, loss: 3.125, accu:0.352\n",
      "Step: 72800, loss: 3.271, accu:0.357\n",
      "Step: 72900, loss: 3.231, accu:0.352\n",
      "Step: 73000, loss: 3.231, accu:0.354\n",
      "Step: 73000, model saved\n",
      "Step: 73100, loss: 3.082, accu:0.381\n",
      "Step: 73200, loss: 3.322, accu:0.375\n",
      "Step: 73300, loss: 3.370, accu:0.350\n",
      "Step: 73400, loss: 3.105, accu:0.399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 73500, loss: 3.155, accu:0.349\n",
      "Step: 73600, loss: 3.031, accu:0.393\n",
      "Step: 73700, loss: 3.217, accu:0.368\n",
      "Step: 73800, loss: 3.191, accu:0.371\n",
      "Step: 73900, loss: 3.160, accu:0.368\n",
      "Step: 74000, loss: 3.377, accu:0.338\n",
      "Step: 74000, model saved\n",
      "Step: 74100, loss: 3.155, accu:0.368\n",
      "Step: 74200, loss: 3.012, accu:0.406\n",
      "Step: 74300, loss: 3.164, accu:0.379\n",
      "Step: 74400, loss: 3.151, accu:0.387\n",
      "Step: 74500, loss: 3.131, accu:0.374\n",
      "Step: 74600, loss: 3.231, accu:0.370\n",
      "Step: 74700, loss: 3.403, accu:0.343\n",
      "Step: 74800, loss: 3.032, accu:0.365\n",
      "Step: 74900, loss: 3.250, accu:0.380\n",
      "Step: 75000, loss: 3.306, accu:0.336\n",
      "Step: 75000, model saved\n",
      "Step: 75100, loss: 3.222, accu:0.390\n",
      "Step: 75200, loss: 3.357, accu:0.354\n",
      "Step: 75300, loss: 3.338, accu:0.360\n",
      "Step: 75400, loss: 3.176, accu:0.354\n",
      "Step: 75500, loss: 3.439, accu:0.329\n",
      "Step: 75600, loss: 3.111, accu:0.357\n",
      "Step: 75700, loss: 3.084, accu:0.380\n",
      "Step: 75800, loss: 3.261, accu:0.363\n",
      "Step: 75900, loss: 3.220, accu:0.384\n",
      "Step: 76000, loss: 3.274, accu:0.354\n",
      "Step: 76000, model saved\n",
      "Step: 76100, loss: 3.258, accu:0.373\n",
      "Step: 76200, loss: 3.539, accu:0.310\n",
      "Step: 76300, loss: 3.234, accu:0.360\n",
      "Step: 76400, loss: 3.265, accu:0.368\n",
      "Step: 76500, loss: 3.115, accu:0.369\n",
      "Step: 76600, loss: 3.361, accu:0.375\n",
      "Step: 76700, loss: 3.213, accu:0.386\n",
      "Step: 76800, loss: 3.238, accu:0.385\n",
      "Step: 76900, loss: 3.335, accu:0.368\n",
      "Step: 77000, loss: 3.133, accu:0.368\n",
      "Step: 77000, model saved\n",
      "Step: 77100, loss: 3.155, accu:0.368\n",
      "Step: 77200, loss: 3.152, accu:0.377\n",
      "Step: 77300, loss: 3.255, accu:0.381\n",
      "Step: 77400, loss: 3.112, accu:0.359\n",
      "Step: 77500, loss: 3.252, accu:0.349\n",
      "Step: 77600, loss: 3.178, accu:0.373\n",
      "Step: 77700, loss: 3.252, accu:0.381\n",
      "Step: 77800, loss: 3.102, accu:0.384\n",
      "Step: 77900, loss: 3.250, accu:0.363\n",
      "Step: 78000, loss: 3.430, accu:0.352\n",
      "Step: 78000, model saved\n",
      "Step: 78100, loss: 3.497, accu:0.326\n",
      "Step: 78200, loss: 3.382, accu:0.345\n",
      "Step: 78300, loss: 3.318, accu:0.374\n",
      "Step: 78400, loss: 3.340, accu:0.347\n",
      "Step: 78500, loss: 3.322, accu:0.343\n",
      "Step: 78600, loss: 3.212, accu:0.374\n",
      "Step: 78700, loss: 3.123, accu:0.380\n",
      "Step: 78800, loss: 3.203, accu:0.355\n",
      "Step: 78900, loss: 3.470, accu:0.360\n",
      "Step: 79000, loss: 3.228, accu:0.374\n",
      "Step: 79000, model saved\n",
      "Step: 79100, loss: 3.530, accu:0.347\n",
      "Step: 79200, loss: 3.104, accu:0.377\n",
      "Step: 79300, loss: 3.236, accu:0.346\n",
      "Step: 79400, loss: 3.279, accu:0.340\n",
      "Step: 79500, loss: 3.344, accu:0.349\n",
      "Step: 79600, loss: 3.411, accu:0.371\n",
      "Step: 79700, loss: 3.404, accu:0.376\n",
      "Step: 79800, loss: 3.193, accu:0.380\n",
      "Step: 79900, loss: 3.064, accu:0.398\n",
      "Step: 80000, loss: 3.318, accu:0.360\n",
      "Step: 80000, model saved\n",
      "Step: 80100, loss: 3.350, accu:0.336\n",
      "Step: 80200, loss: 3.278, accu:0.355\n",
      "Step: 80300, loss: 3.465, accu:0.359\n",
      "Step: 80400, loss: 3.258, accu:0.370\n",
      "Step: 80500, loss: 3.379, accu:0.356\n",
      "Step: 80600, loss: 3.345, accu:0.344\n",
      "Step: 80700, loss: 3.216, accu:0.352\n",
      "Step: 80800, loss: 3.302, accu:0.350\n",
      "Step: 80900, loss: 3.337, accu:0.366\n",
      "Step: 81000, loss: 3.338, accu:0.350\n",
      "Step: 81000, model saved\n",
      "Step: 81100, loss: 3.297, accu:0.352\n",
      "Step: 81200, loss: 3.338, accu:0.369\n",
      "Step: 81300, loss: 3.231, accu:0.375\n",
      "Step: 81400, loss: 3.376, accu:0.327\n",
      "Step: 81500, loss: 3.221, accu:0.382\n",
      "Step: 81600, loss: 3.210, accu:0.357\n",
      "Step: 81700, loss: 3.351, accu:0.343\n",
      "Step: 81800, loss: 3.362, accu:0.334\n",
      "Step: 81900, loss: 3.190, accu:0.387\n",
      "Step: 82000, loss: 3.325, accu:0.370\n",
      "Step: 82000, model saved\n",
      "Step: 82100, loss: 2.951, accu:0.404\n",
      "Step: 82200, loss: 3.085, accu:0.382\n",
      "Step: 82300, loss: 3.161, accu:0.371\n",
      "Step: 82400, loss: 3.146, accu:0.385\n",
      "Step: 82500, loss: 3.207, accu:0.380\n",
      "Step: 82600, loss: 3.202, accu:0.390\n",
      "Step: 82700, loss: 3.083, accu:0.375\n",
      "Step: 82800, loss: 3.219, accu:0.389\n",
      "Step: 82900, loss: 3.392, accu:0.347\n",
      "Step: 83000, loss: 3.164, accu:0.373\n",
      "Step: 83000, model saved\n",
      "Step: 83100, loss: 3.244, accu:0.365\n",
      "Step: 83200, loss: 3.093, accu:0.379\n",
      "Step: 83300, loss: 3.137, accu:0.391\n",
      "Step: 83400, loss: 3.360, accu:0.327\n",
      "Step: 83500, loss: 3.101, accu:0.401\n",
      "Step: 83600, loss: 3.413, accu:0.351\n",
      "Step: 83700, loss: 3.166, accu:0.416\n",
      "Step: 83800, loss: 3.163, accu:0.364\n",
      "Step: 83900, loss: 3.314, accu:0.334\n",
      "Step: 84000, loss: 3.269, accu:0.363\n",
      "Step: 84000, model saved\n",
      "Step: 84100, loss: 3.272, accu:0.360\n",
      "Step: 84200, loss: 3.169, accu:0.393\n",
      "Step: 84300, loss: 3.253, accu:0.381\n",
      "Step: 84400, loss: 3.111, accu:0.369\n",
      "Step: 84500, loss: 3.088, accu:0.414\n",
      "Step: 84600, loss: 3.184, accu:0.385\n",
      "Step: 84700, loss: 3.304, accu:0.354\n",
      "Step: 84800, loss: 3.125, accu:0.381\n",
      "Step: 84900, loss: 3.294, accu:0.356\n",
      "Step: 85000, loss: 3.512, accu:0.320\n",
      "Step: 85000, model saved\n",
      "Step: 85100, loss: 3.238, accu:0.361\n",
      "Step: 85200, loss: 3.005, accu:0.412\n",
      "Step: 85300, loss: 3.188, accu:0.386\n",
      "Step: 85400, loss: 3.170, accu:0.385\n",
      "Step: 85500, loss: 3.183, accu:0.352\n",
      "Step: 85600, loss: 3.177, accu:0.371\n",
      "Step: 85700, loss: 3.125, accu:0.384\n",
      "Step: 85800, loss: 3.360, accu:0.363\n",
      "Step: 85900, loss: 3.053, accu:0.361\n",
      "Step: 86000, loss: 3.201, accu:0.366\n",
      "Step: 86000, model saved\n",
      "Step: 86100, loss: 3.202, accu:0.365\n",
      "Step: 86200, loss: 3.373, accu:0.349\n",
      "Step: 86300, loss: 3.073, accu:0.394\n",
      "Step: 86400, loss: 3.248, accu:0.352\n",
      "Step: 86500, loss: 3.071, accu:0.396\n",
      "Step: 86600, loss: 3.215, accu:0.338\n",
      "Step: 86700, loss: 3.320, accu:0.373\n",
      "Step: 86800, loss: 3.366, accu:0.349\n",
      "Step: 86900, loss: 3.158, accu:0.370\n",
      "Step: 87000, loss: 3.351, accu:0.349\n",
      "Step: 87000, model saved\n",
      "Step: 87100, loss: 3.021, accu:0.377\n",
      "Step: 87200, loss: 3.433, accu:0.366\n",
      "Step: 87300, loss: 3.269, accu:0.356\n",
      "Step: 87400, loss: 3.349, accu:0.344\n",
      "Step: 87500, loss: 3.135, accu:0.374\n",
      "Step: 87600, loss: 3.176, accu:0.351\n",
      "Step: 87700, loss: 3.320, accu:0.369\n",
      "Step: 87800, loss: 3.181, accu:0.405\n",
      "Step: 87900, loss: 3.252, accu:0.351\n",
      "Step: 88000, loss: 3.422, accu:0.352\n",
      "Step: 88000, model saved\n",
      "Step: 88100, loss: 3.124, accu:0.409\n",
      "Step: 88200, loss: 3.129, accu:0.394\n",
      "Step: 88300, loss: 3.276, accu:0.370\n",
      "Step: 88400, loss: 3.423, accu:0.335\n",
      "Step: 88500, loss: 3.218, accu:0.363\n",
      "Step: 88600, loss: 3.090, accu:0.384\n",
      "Step: 88700, loss: 3.157, accu:0.364\n",
      "Step: 88800, loss: 3.402, accu:0.356\n",
      "Step: 88900, loss: 3.334, accu:0.356\n",
      "Step: 89000, loss: 3.290, accu:0.360\n",
      "Step: 89000, model saved\n",
      "Step: 89100, loss: 3.252, accu:0.359\n",
      "Step: 89200, loss: 3.225, accu:0.398\n",
      "Step: 89300, loss: 3.322, accu:0.351\n",
      "Step: 89400, loss: 3.368, accu:0.355\n",
      "Step: 89500, loss: 3.248, accu:0.370\n",
      "Step: 89600, loss: 3.212, accu:0.395\n",
      "Step: 89700, loss: 3.385, accu:0.361\n",
      "Step: 89800, loss: 3.196, accu:0.361\n",
      "Step: 89900, loss: 3.225, accu:0.361\n",
      "Step: 90000, loss: 3.194, accu:0.368\n",
      "Step: 90000, model saved\n",
      "Step: 90100, loss: 3.171, accu:0.373\n",
      "Step: 90200, loss: 3.161, accu:0.356\n",
      "Step: 90300, loss: 3.322, accu:0.394\n",
      "Step: 90400, loss: 3.277, accu:0.338\n",
      "Step: 90500, loss: 3.301, accu:0.364\n",
      "Step: 90600, loss: 3.235, accu:0.387\n",
      "Step: 90700, loss: 3.253, accu:0.354\n",
      "Step: 90800, loss: 3.265, accu:0.370\n",
      "Step: 90900, loss: 3.172, accu:0.390\n",
      "Step: 91000, loss: 3.292, accu:0.369\n",
      "Step: 91000, model saved\n",
      "Step: 91100, loss: 3.191, accu:0.375\n",
      "Step: 91200, loss: 3.164, accu:0.403\n",
      "Step: 91300, loss: 3.119, accu:0.401\n",
      "Step: 91400, loss: 3.203, accu:0.364\n",
      "Step: 91500, loss: 3.095, accu:0.375\n",
      "Step: 91600, loss: 3.233, accu:0.381\n",
      "Step: 91700, loss: 3.196, accu:0.381\n",
      "Step: 91800, loss: 3.264, accu:0.354\n",
      "Step: 91900, loss: 3.259, accu:0.377\n",
      "Step: 92000, loss: 3.215, accu:0.379\n",
      "Step: 92000, model saved\n",
      "Step: 92100, loss: 3.197, accu:0.382\n",
      "Step: 92200, loss: 3.242, accu:0.366\n",
      "Step: 92300, loss: 3.149, accu:0.380\n",
      "Step: 92400, loss: 3.284, accu:0.359\n",
      "Step: 92500, loss: 3.187, accu:0.381\n",
      "Step: 92600, loss: 3.270, accu:0.384\n",
      "Step: 92700, loss: 3.271, accu:0.373\n",
      "Step: 92800, loss: 3.060, accu:0.371\n",
      "Step: 92900, loss: 3.249, accu:0.361\n",
      "Step: 93000, loss: 3.277, accu:0.394\n",
      "Step: 93000, model saved\n",
      "Step: 93100, loss: 3.183, accu:0.385\n",
      "Step: 93200, loss: 3.262, accu:0.360\n",
      "Step: 93300, loss: 3.481, accu:0.364\n",
      "Step: 93400, loss: 3.105, accu:0.391\n",
      "Step: 93500, loss: 3.089, accu:0.419\n",
      "Step: 93600, loss: 3.195, accu:0.386\n",
      "Step: 93700, loss: 3.085, accu:0.386\n",
      "Step: 93800, loss: 3.379, accu:0.350\n",
      "Step: 93900, loss: 3.210, accu:0.373\n",
      "Step: 94000, loss: 3.073, accu:0.377\n",
      "Step: 94000, model saved\n",
      "Step: 94100, loss: 3.326, accu:0.359\n",
      "Step: 94200, loss: 3.167, accu:0.359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 94300, loss: 3.398, accu:0.336\n",
      "Step: 94400, loss: 3.326, accu:0.352\n",
      "Step: 94500, loss: 3.360, accu:0.334\n",
      "Step: 94600, loss: 3.105, accu:0.385\n",
      "Step: 94700, loss: 3.115, accu:0.382\n",
      "Step: 94800, loss: 3.311, accu:0.364\n",
      "Step: 94900, loss: 3.176, accu:0.370\n",
      "Step: 95000, loss: 3.220, accu:0.377\n",
      "Step: 95000, model saved\n",
      "Step: 95100, loss: 3.339, accu:0.346\n",
      "Step: 95200, loss: 3.257, accu:0.387\n",
      "Step: 95300, loss: 3.145, accu:0.400\n",
      "Step: 95400, loss: 3.109, accu:0.370\n",
      "Step: 95500, loss: 3.278, accu:0.346\n",
      "Step: 95600, loss: 3.336, accu:0.355\n",
      "Step: 95700, loss: 3.130, accu:0.356\n",
      "Step: 95800, loss: 3.166, accu:0.391\n",
      "Step: 95900, loss: 3.369, accu:0.343\n",
      "Step: 96000, loss: 3.048, accu:0.381\n",
      "Step: 96000, model saved\n",
      "Step: 96100, loss: 3.146, accu:0.371\n",
      "Step: 96200, loss: 3.196, accu:0.382\n",
      "Step: 96300, loss: 3.313, accu:0.347\n",
      "Step: 96400, loss: 3.275, accu:0.387\n",
      "Step: 96500, loss: 3.091, accu:0.359\n",
      "Step: 96600, loss: 3.151, accu:0.365\n",
      "Step: 96700, loss: 3.331, accu:0.359\n",
      "Step: 96800, loss: 3.265, accu:0.339\n",
      "Step: 96900, loss: 3.329, accu:0.345\n",
      "Step: 97000, loss: 3.149, accu:0.377\n",
      "Step: 97000, model saved\n",
      "Step: 97100, loss: 3.130, accu:0.399\n",
      "Step: 97200, loss: 3.127, accu:0.365\n",
      "Step: 97300, loss: 3.111, accu:0.389\n",
      "Step: 97400, loss: 3.271, accu:0.341\n",
      "Step: 97500, loss: 3.399, accu:0.335\n",
      "Step: 97600, loss: 3.267, accu:0.369\n",
      "Step: 97700, loss: 3.232, accu:0.387\n",
      "Step: 97800, loss: 3.169, accu:0.382\n",
      "Step: 97900, loss: 3.352, accu:0.365\n",
      "Step: 98000, loss: 3.122, accu:0.380\n",
      "Step: 98000, model saved\n",
      "Step: 98100, loss: 3.260, accu:0.368\n",
      "Step: 98200, loss: 3.279, accu:0.361\n",
      "Step: 98300, loss: 3.354, accu:0.374\n",
      "Step: 98400, loss: 3.231, accu:0.352\n",
      "Step: 98500, loss: 3.284, accu:0.339\n",
      "Step: 98600, loss: 3.225, accu:0.375\n",
      "Step: 98700, loss: 3.278, accu:0.382\n",
      "Step: 98800, loss: 3.131, accu:0.412\n",
      "Step: 98900, loss: 3.199, accu:0.363\n",
      "Step: 99000, loss: 3.385, accu:0.357\n",
      "Step: 99000, model saved\n",
      "Step: 99100, loss: 3.163, accu:0.391\n",
      "Step: 99200, loss: 3.147, accu:0.356\n",
      "Step: 99300, loss: 3.155, accu:0.394\n",
      "Step: 99400, loss: 3.432, accu:0.352\n",
      "Step: 99500, loss: 3.141, accu:0.375\n",
      "Step: 99600, loss: 3.200, accu:0.375\n",
      "Step: 99700, loss: 3.020, accu:0.405\n",
      "Step: 99800, loss: 3.316, accu:0.385\n",
      "Step: 99900, loss: 3.234, accu:0.381\n",
      "Step: 100000, loss: 3.254, accu:0.368\n",
      "Step: 100000, model saved\n"
     ]
    }
   ],
   "source": [
    "training_steps = 100000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    writer = tf.summary.FileWriter(output_dir, sess.graph)\n",
    "    for i in range(training_steps):\n",
    "        (batch_img_features,\n",
    "         batch_sentence_ids,\n",
    "         batch_weights, _) = caption_data.next_batch(hps.batch_size)\n",
    "        input_vals = (batch_img_features, batch_sentence_ids, batch_weights, hps.keep_prob)\n",
    "        feed_dict = dict(zip(placeholders, input_vals))\n",
    "        fetches = (global_step, loss, accuracy, train_op)\n",
    "        should_log = (i + 1) % hps.log_frequent == 0\n",
    "        should_save = (i + 1) % hps.save_frequent == 0\n",
    "        if should_log:\n",
    "            fetches += tuple([summary_op])\n",
    "        \n",
    "        outputs = sess.run(fetches, feed_dict = feed_dict)\n",
    "        global_step_val, loss_val, accuracy_val = outputs[0:3]\n",
    "        if should_log:\n",
    "            summary_str = outputs[-1]\n",
    "            writer.add_summary(summary_str, global_step_val)\n",
    "            print(\"Step: %5d, loss: %3.3f, accu:%3.3f\" % (global_step_val, loss_val, accuracy_val))\n",
    "        \n",
    "        if should_save:\n",
    "            model_save_file = os.path.join(output_dir, \"image_caption\")\n",
    "            print(\"Step: %5d, model saved\" % global_step_val)\n",
    "            saver.save(sess, model_save_file, global_step=global_step_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep_learning]",
   "language": "python",
   "name": "deep_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
